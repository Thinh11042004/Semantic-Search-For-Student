import os
import logging
from fastapi import FastAPI, Body, Query
from sentence_transformers import SentenceTransformer
import psycopg2
from PyPDF2 import PdfReader
import docx 
from fastapi.responses import JSONResponse
from typing import Union, List
import numpy as np
import logging
import re


# T·∫°o th∆∞ m·ª•c logs n·∫øu ch∆∞a c√≥
if not os.path.exists("logs"):
    os.makedirs("logs")

# Thi·∫øt l·∫≠p ghi log
logging.basicConfig(
    filename="logs/upload.log",
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)

app = FastAPI()
model = SentenceTransformer("sentence-transformers/all-mpnet-base-v2")  # 768 chi·ªÅu 



# K·∫øt n·ªëi PostgreSQL
conn = psycopg2.connect(
    host="semantic_search_db",  
    port=5432,
    user="admin",
    password="123456",
    database="StudentFormDB"
)
cursor = conn.cursor()

# Helper function ƒë·ªÉ ƒë·ªçc file PDF
def extract_text_from_pdf(pdf_path):
    text = ""
    with open(pdf_path, "rb") as file:
        reader = PdfReader(file)
        for page in reader.pages:
            page_text = page.extract_text()
            if page_text:
                text += page_text
    return text

# Helper function ƒë·ªÉ ƒë·ªçc file DOCX
def extract_text_from_docx(docx_path):
    doc = docx.Document(docx_path)
    return "\n".join([para.text for para in doc.paragraphs])


# H√†m ki·ªÉm tra xem t√™n file ƒë√£ t·ªìn t·∫°i trong c∆° s·ªü d·ªØ li·ªáu ch∆∞a (ƒê√¢y l√† ph·∫ßn thay ƒë·ªïi)
def is_file_exists(title):  
    cursor.execute("SELECT COUNT(*) FROM forms WHERE title = %s", (title,))
    count = cursor.fetchone()[0]
    return count > 0  # N·∫øu count > 0, nghƒ©a l√† file ƒë√£ t·ªìn t·∫°i



# H√†m x√≥a t·∫•t c·∫£ c√°c b·∫£n ghi tr√πng t√™n file
def delete_duplicate_files():
    try:
        cursor.execute("""
            DELETE FROM forms
            WHERE ctid NOT IN (
                SELECT min(ctid)
                FROM documents
                GROUP BY title
            );
        """)  # X√≥a t·∫•t c·∫£ c√°c b·∫£n ghi tr√πng, ch·ªâ gi·ªØ l·∫°i b·∫£n ghi ƒë·∫ßu ti√™n c√≥ c√πng title
        conn.commit()
        logging.info("ƒê√£ x√≥a t·∫•t c·∫£ c√°c b·∫£n ghi tr√πng t√™n file.")
    except Exception as e:
        logging.error(f"L·ªói khi x√≥a file tr√πng: {e}")
        conn.rollback()


# H√†m upload file (d√πng chung cho API v√† auto load)
def upload_file_to_db(file_path):
    title = os.path.basename(file_path)
    
    if is_file_exists(title):  # N·∫øu file ƒë√£ t·ªìn t·∫°i
        logging.info(f"File '{title}' ƒë√£ t·ªìn t·∫°i. X√≥a file tr√πng...")
        delete_duplicate_files()  # X√≥a file tr√πng
    
    content = ""
    if file_path.endswith(".pdf"):
        content = extract_text_from_pdf(file_path)
    elif file_path.endswith(".docx"):
        content = extract_text_from_docx(file_path)
    else:
        logging.warning(f"B·ªè qua file kh√¥ng h·ªó tr·ª£: {file_path}")
        return {"error": "Unsupported file type"}
    
    embedding = model.encode(content).tolist()
    
    try:
        cursor.execute(
            "INSERT INTO forms (title, content, embedding) VALUES (%s, %s, %s)",
            (title, content, embedding)
        )
        conn.commit()
        logging.info(f"Uploaded: {title}")
        return {"status": "uploaded", "title": title}
    except Exception as e:
        logging.error(f"L·ªói khi upload file: {e}")
        conn.rollback()
        return {"error": f"Failed to upload file: {e}"}


@app.get("/search")
def semantic_search(
    query: str = Query(..., description="C√¢u truy v·∫•n t√¨m ki·∫øm"),
    top_k: int = Query(5, description="S·ªë l∆∞·ª£ng k·∫øt qu·∫£ mu·ªën tr·∫£ v·ªÅ")
):
    """
    ‚úÖ API Semantic Search n√¢ng cao:
    - M√£ h√≥a truy v·∫•n b·∫±ng S-BERT
    - T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng cosine
    - L·ªçc ƒëo·∫°n vƒÉn ph√π h·ª£p
    - G·ª£i √Ω fallback n·∫øu kh√¥ng c√≥ ƒëo·∫°n ch·ª©a t·ª´ kh√≥a
    - Tr·∫£ l√Ω do + ƒëi·ªÉm s·ªë cho t·ª´ng k·∫øt qu·∫£
    """
    logging.info(f"üîç Semantic search: {query}")
    try:
        # ‚úÖ 1. M√£ h√≥a truy v·∫•n b·∫±ng S-BERT
        query_vec = model.encode(query).tolist()

        # ‚úÖ 2. Truy v·∫•n d·ªØ li·ªáu t·ª´ DB
        cursor.execute("SELECT title, content, embedding FROM forms")
        rows = cursor.fetchall()

        def cosine_similarity(a, b):
            # ‚úÖ 3. √âp ki·ªÉu an to√†n sang float32 (S·ª¨A M·ªöI)
            a = np.array(a, dtype=np.float32)
            b = np.array(eval(b), dtype=np.float32) if isinstance(b, str) else np.array(b, dtype=np.float32)
            return float(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b)))

        scored = []
        for title, content, embedding in rows:
            try:
                score = cosine_similarity(query_vec, embedding)
                scored.append((title, content, score))
            except Exception as vector_err:
                logging.warning(f"‚ö†Ô∏è B·ªè qua vector l·ªói: {vector_err}")
                continue

        if not scored:
            return JSONResponse(status_code=404, content={"message": "Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ ph√π h·ª£p."})

        # ‚úÖ 4. L·∫•y top_k k·∫øt qu·∫£ theo ƒëi·ªÉm
        top_results = sorted(scored, key=lambda x: x[2], reverse=True)[:top_k]

        final_results = []
        for title, content, score in top_results:
            sentences = re.split(r'[.?!]\s+', content)
            matched = [s for s in sentences if query.lower() in s.lower()]
            snippet = " ".join(matched)[:300] + "..." if matched else content[:300] + "..."
            final_results.append({
                "title": title,
                "snippet": snippet,
                "similarity_score": round(score, 4),
                "reason": "T√¨m th·∫•y c√¢u ch·ª©a t·ª´ kh√≥a truy v·∫•n" if matched else "G·ª£i √Ω theo ƒë·ªô t∆∞∆°ng ƒë·ªìng ng·ªØ nghƒ©a"
            })

        return {
            "query": query,
            "top_matches": final_results
        }

    except Exception as e:
        logging.error(f"‚ùå Search error: {e}")
        return JSONResponse(
            status_code=500,
            content={"error": "Search failed", "detail": str(e)}
        )

#API Top-K t√¨m ki·∫øm k bi·ªÉu m·∫´u
@app.post("/top-k")
def top_k_search(query: str = Body(...), k: int = Body(...)):
    logging.info(f"üîç ƒêang t√¨m ki·∫øm v·ªõi truy v·∫•n: {query}, Top {k} k·∫øt qu·∫£")

    try:
        # M√£ h√≥a truy v·∫•n th√†nh vector
        query_embedding = model.encode(query).tolist()  # Chuy·ªÉn ƒë·ªïi th√†nh Python list

        # Truy v·∫•n PostgreSQL ƒë·ªÉ l·∫•y top-K k·∫øt qu·∫£ t√¨m ki·∫øm
        cursor.execute("""
            SELECT title, content
            FROM forms
            ORDER BY embedding <=> %s::vector  -- So s√°nh vector
            LIMIT %s;
        """, (query_embedding, k))  # Truy·ªÅn v√†o query_embedding d∆∞·ªõi d·∫°ng list v√† k

        results = cursor.fetchall()
        
        # Tr·∫£ v·ªÅ k·∫øt qu·∫£
        if results:
            return {
                "query": query,
                "top_k_results": [
                    {"title": result[0], "content": result[1][:500] + "..."} for result in results
                ]
            }
        else:
            return {
                "query": query,
                "message": f"Kh√¥ng t√¨m th·∫•y {k} bi·ªÉu m·∫´u ph√π h·ª£p."
            }
    except Exception as e:
        logging.error(f"L·ªói trong qu√° tr√¨nh t√¨m ki·∫øm: {e}")
        cursor.execute("ROLLBACK;")  # H·ªßy giao d·ªãch n·∫øu c√≥ l·ªói
        return {"error": f"Top-K search failed: {e}"}



# ‚úÖ API: Nh·∫≠n vƒÉn b·∫£n, tr·∫£  vector
@app.post("/get-embedding")
def get_embedding(text: Union[str, List[str]] = Body(...)):
  
    try:
        if isinstance(text, str):
            text = [text]
        text = [t[:5000] for t in text]  # Gi·ªõi h·∫°n vƒÉn b·∫£n d√†i
        embeddings = model.encode(text).tolist()
        return {
            "embedding": embeddings[0] if len(embeddings) == 1 else embeddings
        }
    except Exception as e:
        logging.error(f"L·ªói khi sinh embedding: {e}")
        return JSONResponse(
            status_code=500,
            content={"status": "error", "message": f"L·ªói khi sinh embedding: {e}"}
        )
  